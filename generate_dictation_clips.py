# functions/generate_dictation_clips.py

import os
import json
import re
import html
from pathlib import Path

import requests  # pip install requests

# ============================
# ğŸ”§ è¨­å®š
# ============================

# ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆgenerate_dictation_clips.pyï¼‰ã®å ´æ‰€ã‚’åŸºæº–ã«ãƒ‘ã‚¹ã‚’ä½œã‚‹
ROOT_DIR = Path(__file__).resolve().parent
LESSON_DIR = ROOT_DIR / "scripts"  / "Level5" / "Lesson3" / "D"

DICTATION_JSON_PATH = LESSON_DIR / "dictation.json"
OUTPUT_BASE_DIR = LESSON_DIR / "dictation_audio"

# Azure Speech ã®ã‚­ãƒ¼ã¨ãƒªãƒ¼ã‚¸ãƒ§ãƒ³ã¯ç’°å¢ƒå¤‰æ•°ã‹ã‚‰èª­ã‚€
AZURE_SPEECH_KEY = os.environ.get("AZURE_SPEECH_KEY")
AZURE_SPEECH_REGION = os.environ.get("AZURE_SPEECH_REGION", "japaneast")

if not AZURE_SPEECH_KEY:
  raise RuntimeError("ç’°å¢ƒå¤‰æ•° AZURE_SPEECH_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")


# ============================
# ğŸ§  ç©ºæ‰€ï¼ˆ______ï¼‰ã‚’ answers ã§åŸ‹ã‚ã‚‹
# ============================

def fill_blanks(template: str, answers: list[str]) -> str:
    """
    sentence / sentence1 / sentence2 ã®ä¸­ã® ______ ã‚’
    answers ã§å‰ã‹ã‚‰é †ç•ªã«åŸ‹ã‚ã¦ã„ãã€‚
    ã‚¢ãƒ³ãƒ€ãƒ¼ã‚¹ã‚³ã‚¢ã®é•·ã•ã¯ 3 å€‹ä»¥ä¸Šãªã‚‰ä½•ã§ã‚‚ OK ã«ã—ã¦ã„ã‚‹ã€‚
    """
    idx = 0

    def repl(match: re.Match) -> str:
        nonlocal idx
        if idx < len(answers):
            word = answers[idx]
            idx += 1
            return word
        # äºˆæƒ³å¤–ã« blanks ãŒå¤šã‹ã£ãŸå ´åˆã¯ãã®ã¾ã¾æ®‹ã™
        return match.group(0)

    # ___ ä»¥ä¸Šã®é€£ç¶šã‚¢ãƒ³ãƒ€ãƒ¼ã‚¹ã‚³ã‚¢ã‚’ç½®æ›å¯¾è±¡ã«ã™ã‚‹
    filled = re.sub(r"_{3,}", repl, template)
    # ç©ºç™½ãŒãƒ€ãƒ–ã¤ã„ãŸã¨ã“ã‚ã‚’è»½ãæ•´å½¢
    filled = re.sub(r"\s+", " ", filled).strip()
    return filled


def build_question_text(part: str, q: dict) -> str:
    """
    DictationQuestion ã”ã¨ã« TTS ã«æŠ•ã’ã‚‹æœ€çµ‚è‹±æ–‡ã‚’ä½œã‚‹ã€‚
    - Part A / C: sentence + answers
    - Part B: sentence1 + sentence2 + answers
    """
    answers = q.get("answers", [])

    if part in ("A", "C"):
        sentence = q["sentence"]
        return fill_blanks(sentence, answers)

    if part == "B":
        s1 = q["sentence1"]
        s2 = q["sentence2"]
        # 2 æ–‡ã‚’ã¤ãªã’ã¦ã‹ã‚‰ä¸€æ°—ã« blanks ã‚’åŸ‹ã‚ã‚‹
        combined = f"{s1} {s2}"
        return fill_blanks(combined, answers)

    raise ValueError(f"Unknown part: {part}")


# ============================
# ğŸ”Š Azure TTS ã§ WAV ç”Ÿæˆ
# ============================

def synthesize_to_wav(text: str, out_path: Path):
    """
    ä¸ãˆã‚‰ã‚ŒãŸ text ã‚’ Azure TTS (JennyNeural) ã§ WAV ã«ã—ã¦ä¿å­˜ã€‚
    """
    endpoint = f"https://{AZURE_SPEECH_REGION}.tts.speech.microsoft.com/cognitiveservices/v1"

    # SSML ã§é€ã‚‹
    ssml = f"""
<speak version="1.0" xml:lang="en-US">
  <voice xml:lang="en-US" xml:gender="Female" name="en-US-JennyNeural">
  <prosody rate="0.8">
    {html.escape(text)}
    </prosody>
  </voice>
</speak>
""".strip()

    headers = {
        "Ocp-Apim-Subscription-Key": AZURE_SPEECH_KEY,
        "Content-Type": "application/ssml+xml",
        "X-Microsoft-OutputFormat": "riff-16khz-16bit-mono-pcm",
        "User-Agent": "shadow-speak-dictation-generator",
    }

    print(f"  ğŸ”ˆ TTS: '{text}'")
    resp = requests.post(endpoint, headers=headers, data=ssml.encode("utf-8"))

    if resp.status_code != 200:
        raise RuntimeError(
            f"TTS å¤±æ•—: HTTP {resp.status_code} - {resp.text[:200]}"
        )

    out_path.parent.mkdir(parents=True, exist_ok=True)
    with open(out_path, "wb") as f:
        f.write(resp.content)

    print(f"  âœ… Saved: {out_path.relative_to(ROOT_DIR)}")


# ============================
# ğŸš€ ãƒ¡ã‚¤ãƒ³å‡¦ç†
# ============================

def main():
    print(f"ğŸ“„ Loading dictation json: {DICTATION_JSON_PATH}")
    with open(DICTATION_JSON_PATH, "r", encoding="utf-8") as f:
        data = json.load(f)

    lesson_id = data.get("lessonId", "UNKNOWN")
    parts = data["parts"]  # A / B / C

    for part_label, questions in parts.items():
        print(f"\n=== Part {part_label} ===")
        for q in questions:
            qid = q["id"]  # A1, A2, ...
            text = build_question_text(part_label, q)

            # ä¾‹: scripts/Levels/Level5/Lesson3/dictation_audio/A/A1.wav
            out_path = OUTPUT_BASE_DIR / part_label / f"{qid}.wav"
            print(f"â–¶ {lesson_id} / Part {part_label} / {qid}")
            synthesize_to_wav(text, out_path)

    print("\nğŸ‰ All dictation clips generated!")


if __name__ == "__main__":
    main()
