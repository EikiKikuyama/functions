"use strict";

/* =========================================================
   ğŸ”§ Import & Setup (Gen2)
   ========================================================= */
const { setGlobalOptions } = require("firebase-functions/v2");
const { onObjectFinalized } = require("firebase-functions/v2/storage");
const { onDocumentCreated } = require("firebase-functions/v2/firestore");
const { onCall } = require("firebase-functions/v2/https");
const { defineSecret } = require("firebase-functions/params");

const admin = require("firebase-admin");
const fs = require("fs");
const path = require("path");
const os = require("os");
const fetch = require("node-fetch");
const FormData = require("form-data");

// ğŸ”¥ ffmpegï¼ˆWebM â†’ WAV å¤‰æ›ï¼‰
const ffmpegPath = require("ffmpeg-static");
const ffmpeg = require("fluent-ffmpeg");

// ---- Firebase init
admin.initializeApp({ projectId: "shadow-speak-school" });
const db = admin.firestore();
const storage = admin.storage();

// ---- Global options
setGlobalOptions({
  region: "asia-northeast1",
  timeoutSeconds: 540,
  memoryMiB: 1024,
});

// ---- Secrets
const OPENAI_API_KEY = defineSecret("OPENAI_API_KEY");
const SPEECH_KEY = defineSecret("SPEECH_KEY");
const SPEECH_REGION = defineSecret("SPEECH_REGION");

/* =========================================================
   ğŸ”§ Path helpers
   ========================================================= */

function isOfficialPath(p) {
  return typeof p === "string" && p.startsWith("official/");
}
function isWebm(p, ct) {
  return (ct && ct.includes("webm")) || (typeof p === "string" && p.toLowerCase().endsWith(".webm"));
}
function isAudioFile(p) {
  return typeof p === "string" && /\.(wav|mp3|m4a|aac|ogg)$/i.test(p);
}
function isSubtitlesJson(p) {
  return typeof p === "string" && p.toLowerCase().endsWith("_subtitles.json");
}
function isDictationJson(p) {
  return isOfficialPath(p) && p.toLowerCase().endsWith("/dictation.json");
}
function isOfficialTxt(p) {
  return isOfficialPath(p) && p.toLowerCase().endsWith(".txt");
}
function toDocIdFromPath(p) {
  return (p || "").replace(/\//g, "__");
}

function extractMetaFromOfficialPath(filePath) {
  const parts = (filePath || "").split("/");

  // official/Level5/Lesson1/A/passage2/xxx
  const level = parts[1] || "";
  const lesson = parts[2] || "";
  const pattern = parts[3] || "";

  const passage = extractPassageNumber(filePath); // null or number
  return { level, lesson, pattern, passage };
}



// passageç•ªå·ã‚’ãƒ‘ã‚¹ã‹ã‚‰å–ã‚‹: .../passage3/..._subtitles.json
function extractPassageNumber(filePath) {
  const m = (filePath || "").match(/\/passage(\d+)\//i);
  return m ? Number(m[1]) : null;
}
// =========================================================
// ğŸ›ï¸ TTS è¨­å®šï¼ˆLevel / Pattern ã§å£°ï¼†é€Ÿåº¦ã‚’å¤‰ãˆã‚‹ï¼‰
// =========================================================

const LEVEL_RATE = {
  Level1: "-30%",
  Level2: "-27%",
  Level3: "-21%",
  Level4: "-15%",
  Level5: "-12%",
  Level6: "-3%",
};

// ãƒ‘ã‚¿ãƒ¼ãƒ³ã”ã¨ã«å£°ã‚’å¤‰ãˆãŸã„ãªã‚‰ã“ã“ã§å·®ã—æ›¿ãˆã‚‹
const PATTERN_VOICE = {
  A: "en-US-GuyNeural",
  B: "en-US-JennyNeural",
  C: "en-US-AriaNeural",
  D: "en-US-DavisNeural",
  E: "en-US-AmberNeural",
  F: "en-US-BrandonNeural",
  evaluation: "en-US-JennyNeural",
};

function pickVoiceName({ pattern }) {
  return PATTERN_VOICE[pattern] || "en-US-JennyNeural";
}

function pickRate({ level }) {
  return LEVEL_RATE[level] || "0%";
}

// official/Level5/Lesson1/D/passage1/listening.txt -> listening.wav
function toTtsAudioOutPathFromTxt(txtPath) {
  if (typeof txtPath !== "string") return null;
  // æ‹¡å¼µå­ã ã‘ wav ã«ã™ã‚‹ï¼ˆmp3ã«ã—ãŸã„ãªã‚‰å¾Œã§ffmpegã§å¤‰æ›ï¼‰
  return txtPath.replace(/\.txt$/i, ".wav");
}

function levelToNumber(levelStr) {
  const m = String(levelStr || "").match(/(\d+)/);
  return m ? Number(m[1]) : null;
}
function lessonToNumber(lessonStr) {
  const m = String(lessonStr || "").match(/(\d+)/);
  return m ? Number(m[1]) : null;
}
function legacyDocId(levelStr, lessonStr, pattern) {
  return `Level_${levelToNumber(levelStr)}_Lesson${lessonToNumber(lessonStr)}_${pattern}`;
}
function legacyId(levelStr, lessonStr, pattern) {
  const ln = levelToNumber(levelStr);
  const lesn = lessonToNumber(lessonStr);
  return `L${ln}_${pattern}_${String(lesn).padStart(2, "0")}`;
}

function upsertSortedImagePaths(existing = [], addPath) {
  const set = new Set(Array.isArray(existing) ? existing : []);
  set.add(addPath);
  const arr = Array.from(set);

  // img_..._a.png ã® a,b,c,d é †
  arr.sort((p1, p2) => {
    const a1 = (p1.match(/_([a-d])\.(png|jpg|jpeg)$/i) || [])[1] || "z";
    const a2 = (p2.match(/_([a-d])\.(png|jpg|jpeg)$/i) || [])[1] || "z";
    return a1.localeCompare(a2);
  });

  return arr;
}

exports.buildLegacyMaterialsOnOfficialUpload = onObjectFinalized(async (event) => {
  const filePath = event.data.name;
  if (!filePath) return;

  // å…¬å¼æ•™æã ã‘å¯¾è±¡
  if (!isOfficialPath(filePath)) return;

  // evaluation ã¯å¯¾è±¡å¤–ï¼ˆå¿…è¦ãªã‚‰åˆ¥æ‰±ã„ï¼‰
  const { level, lesson, pattern, passage } = extractMetaFromOfficialPath(filePath);
  if (!level || !lesson || !pattern) return;
  if (pattern === "evaluation") return;

    // âœ… ãƒ¬ãƒƒã‚¹ãƒ³å˜ä½ dictation.jsonï¼ˆpassageå¤–ï¼‰ã‚’æ‹¾ã†
  if (!Number.isFinite(passage)) {
    const filename = filePath.split("/").pop() || "";
    if (filename.toLowerCase() === "dictation.json") {
      const docId = legacyDocId(level, lesson, pattern);
      await db.collection("materials").doc(docId).set(
        {
          dictationPath: filePath,
          mode: admin.firestore.FieldValue.arrayUnion("dictation"),
          updatedAt: admin.firestore.FieldValue.serverTimestamp(),
        },
        { merge: true }
      );
      console.log(`âœ… set top-level dictationPath: ${docId} -> ${filePath}`);
    }
    return;
  }

  
  // passage é…ä¸‹ã®ã¿å¯¾è±¡ï¼ˆA-F ã® passageNï¼‰
  if (!Number.isFinite(passage)) return;

  // ä¾‹: official/Level5/Lesson1/A/passage2/img_L5_L01_02_a.png
  const filename = filePath.split("/").pop() || "";

  const docId = legacyDocId(level, lesson, pattern);
  const ref = db.collection("materials").doc(docId);

  await db.runTransaction(async (tx) => {
    const snap = await tx.get(ref);
    const data = snap.exists ? snap.data() : {};

    const passages = Array.isArray(data.passages) ? data.passages : [];

    // passageã‚’å–å¾—/ä½œæˆ
    let p = passages.find((x) => Number(x.id) === passage);
    if (!p) {
      p = { id: passage, order: passage, durationSec: 0 };
      passages.push(p);
    }

    // ã©ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã§åŸ‹ã‚ã‚‹
    if (/\.(mp3|wav)$/i.test(filename) && filename.includes("listening")) {
      p.audioPath = filePath;

    } else if (filename.toLowerCase().includes("subtitles") && filename.toLowerCase().endsWith(".json")) {
      p.subtitlePath = filePath;

    } else if (filename.toLowerCase().endsWith("listening.txt")) {
      p.scriptPath = filePath;  } 
      
      else if (
  filename.toLowerCase().endsWith("listening_questions.json") ||
  filename.toLowerCase().endsWith("listening_question.json")
) {
  p.questionsPath = filePath;

    } else if (filename.toLowerCase().endsWith("dictation.json") || filename.toLowerCase().endsWith("_dictation.json")) {
      p.dictationPath = filePath;
    } else if (/^img_.*_([a-d])\.(png|jpg|jpeg)$/i.test(filename)) {
      p.imagePaths = upsertSortedImagePaths(p.imagePaths, filePath);
      p.imagePath = p.imagePaths[0]; // äº’æ›ç”¨
    }

    // mode
    const modeSet = new Set(Array.isArray(data.mode) ? data.mode : ["listening", "overlapping"]);
    if (p.dictationPath) modeSet.add("dictation");

    // top-level
    const legacy = {
  title: data.title ?? `${lesson}`, // ä¾‹: "Lesson1"
  level: data.level ?? level,
  lesson: data.lesson ?? lessonToNumber(lesson),
  pattern: data.pattern ?? pattern,
  id: data.id ?? legacyId(level, lesson, pattern),
  mode: Array.from(modeSet),
  passages,
  updatedAt: admin.firestore.FieldValue.serverTimestamp(),
};


    tx.set(ref, legacy, { merge: true });
  });

  console.log(`âœ… materials updated: ${docId} passage=${passage} file=${filename}`);
});

/* =========================================================
   ğŸ§ 1) ffmpeg: WebM â†’ WAV è‡ªå‹•å¤‰æ›
   ========================================================= */
exports.convertWebmToWav = onObjectFinalized(
  {
    region: "asia-northeast1",
    timeoutSeconds: 540,
    memory: "1GiB",
  },
  async (event) => {
    const object = event.data;
    const filePath = object.name;
    const type = object.contentType;

    if (!filePath) return;
    if (!isWebm(filePath, type)) return;

    const bucket = storage.bucket(object.bucket);
    const fileName = path.basename(filePath);
    const tmpIn = path.join(os.tmpdir(), fileName);
    const wavName = fileName.replace(/\.webm$/i, ".wav");
    const tmpOut = path.join(os.tmpdir(), wavName);

    await bucket.file(filePath).download({ destination: tmpIn });
    console.log("â¬‡ï¸ Downloaded:", tmpIn);

    ffmpeg.setFfmpegPath(ffmpegPath);

    await new Promise((resolve, reject) => {
      ffmpeg(tmpIn)
        .toFormat("wav")
        .on("end", () => resolve())
        .on("error", reject)
        .save(tmpOut);
    });

    const wavStoragePath = filePath.replace(/\.webm$/i, ".wav");
    await bucket.upload(tmpOut, {
      destination: wavStoragePath,
      metadata: { contentType: "audio/wav" },
    });
    console.log("â¬†ï¸ Uploaded WAV:", wavStoragePath);

    fs.unlinkSync(tmpIn);
    fs.unlinkSync(tmpOut);
  }
);

/* =========================================================
   ğŸ§  2) Whisper å‘¼ã³å‡ºã—
   ========================================================= */
async function callWhisperVerboseJson(tmpPath, { wantWords = true } = {}) {
  const apiKey = process.env.OPENAI_API_KEY;
  if (!apiKey) throw new Error("OPENAI_API_KEY missing");

  const form = new FormData();
  form.append("file", fs.createReadStream(tmpPath));
  form.append("model", "whisper-1");
  form.append("response_format", "verbose_json");
  if (wantWords) form.append("timestamp_granularities[]", "word");
  form.append("timestamp_granularities[]", "segment");

  const res = await fetch("https://api.openai.com/v1/audio/transcriptions", {
    method: "POST",
    headers: { Authorization: `Bearer ${apiKey}`, ...form.getHeaders() },
    body: form,
  });

  const json = await res.json();
  if (!res.ok) throw new Error(JSON.stringify(json));
  return json;
}

/* =========================================================
   ğŸª„ 3) Whisper â†’ ã‚¢ãƒ—ãƒªç”¨ JSONï¼ˆwords fallbackä»˜ãï¼‰
   ========================================================= */
function formatWhisperToAppJson(result) {
  const out = {
    text: result.text || "",
    segments: [],
    language: result.language || "en",
  };

  if (!Array.isArray(result.segments)) return out;

  const globalWords = Array.isArray(result.words)
    ? result.words.map((w) => ({
        word: (w.word || "").trim(),
        start: Number(w.start || 0),
        end: Number(w.end || 0),
        probability: w.probability ?? 1,
      }))
    : [];

  out.segments = result.segments.map((seg, idx) => {
    const start = Number(seg.start || 0);
    const end = Number(seg.end || 0);
    const dur = Math.max(0, end - start);

    let segWords = [];

    if (Array.isArray(seg.words) && seg.words.length > 0) {
      segWords = seg.words.map((w) => ({
        word: (w.word || "").trim(),
        start: Number(w.start || start),
        end: Number(w.end || start),
        probability: w.probability ?? 1,
      }));
    } else if (globalWords.length > 0) {
      segWords = globalWords.filter((w) => w.start >= start - 0.05 && w.start < end + 0.05);
    }

    if (segWords.length === 0) {
      const tokens = (seg.text || "").split(/\s+/).filter(Boolean);

      const rawDur = dur;
      let headPad = 0.2;
      let tailPad = 0.6;

      const maxPad = rawDur * 0.4;
      let totalPad = headPad + tailPad;
      if (totalPad > maxPad && totalPad > 0) {
        const scale = maxPad / totalPad;
        headPad *= scale;
        tailPad *= scale;
      }

      const usableStart = start + headPad;
      const usableDur = Math.max(0, rawDur - headPad - tailPad);
      const slice = tokens.length > 0 ? usableDur / Math.max(tokens.length, 1) : 0;

      segWords = tokens.map((t, i) => ({
        word: t,
        start: usableStart + i * slice,
        end: usableStart + (i + 1) * slice,
        probability: 1,
      }));
    }

    return {
      id: idx,
      seek: 0,
      start,
      end,
      text: seg.text || "",
      tokens: seg.tokens || [],
      temperature: seg.temperature || 0,
      avg_logprob: seg.avg_logprob || 0,
      compression_ratio: seg.compression_ratio || 1,
      no_speech_prob: seg.no_speech_prob || 0,
      words: segWords,
    };
  });

  return out;
}

/* =========================================================
   ğŸ§ 4) Storage: éŸ³å£° â†’ _subtitles.json ç”Ÿæˆ
   ========================================================= */
exports.generateSubtitleJson = onObjectFinalized(
  { region: "asia-northeast1", secrets: [OPENAI_API_KEY] },
  async (event) => {
    const object = event.data;
    const filePath = object.name;
    const contentType = object.contentType;
    if (!filePath) return;

    console.log("ğŸŸ¢ generateSubtitleJson:", filePath);

    // WebMã¯ convertWebmToWav ã«ä»»ã›ã‚‹
    if (isWebm(filePath, contentType)) {
      console.log("â­ Skip: handled by convertWebmToWav");
      return;
    }

    // éŸ³å£°ã ã‘
    if (!isAudioFile(filePath)) return;

    const bucket = storage.bucket(object.bucket);
    const tmpIn = path.join(os.tmpdir(), path.basename(filePath));
    await bucket.file(filePath).download({ destination: tmpIn });

    const transcriptPath = filePath.replace(/\.(wav|mp3|m4a|aac|ogg)$/i, "_subtitles.json");

    try {
      let res = await callWhisperVerboseJson(tmpIn, { wantWords: true });
      if (!res.segments?.some((s) => s.words?.length)) {
        res = await callWhisperVerboseJson(tmpIn, { wantWords: false });
      }

      const formatted = formatWhisperToAppJson(res);
      const tmpJson = path.join(os.tmpdir(), path.basename(transcriptPath));
      fs.writeFileSync(tmpJson, JSON.stringify(formatted, null, 2));

      await bucket.upload(tmpJson, {
        destination: transcriptPath,
        metadata: { contentType: "application/json" },
      });

      console.log("ğŸ“„ Uploaded JSON:", transcriptPath);
      fs.unlinkSync(tmpJson);
    } catch (e) {
      console.error("âŒ Whisper failed:", e);
    } finally {
      fs.unlinkSync(tmpIn);
    }
  }
);

/* =========================================================
   ğŸ« 5) Firestore: ã‚¯ãƒ©ã‚¹ä½œæˆ â†’ å…¬å¼æ•™æã‚³ãƒ”ãƒ¼
   ========================================================= */
exports.copyOfficialMaterialsOnClassCreate = onDocumentCreated(
  { document: "schools/{schoolId}/classes/{classId}", region: "asia-northeast1" },
  async (event) => {
    const { schoolId, classId } = event.params;

    const snap = await db
      .collection("schools")
      .doc(schoolId)
      .collection("materials")
      .where("type", "==", "Official")
      .get();

    if (snap.empty) return;

    const batch = db.batch();
    snap.forEach((doc) => {
      batch.set(
        db.collection("schools").doc(schoolId).collection("classes").doc(classId).collection("materials").doc(doc.id),
        {
          ...doc.data(),
          visible: true,
          copiedAt: new Date(),
          sourceType: "Official",
        }
      );
    });

    await batch.commit();
  }
);

/* =========================================================
   â˜ï¸ 6) Callable: URL â†’ Whisper å³æ™‚è§£æ
   ========================================================= */
exports.transcribeFromUrl = onCall(
  { region: "asia-northeast1", secrets: [OPENAI_API_KEY] },
  async (req) => {
    const audioUrl = req.data.audioUrl || req.data.sourceUrl;
    if (!audioUrl) throw new Error("audioUrl required");

    const audioResp = await fetch(audioUrl);
    if (!audioResp.ok) throw new Error(`Failed to fetch audio: ${audioResp.status} ${audioResp.statusText}`);
    const buf = Buffer.from(await audioResp.arrayBuffer());

    const form = new FormData();
    form.append("file", buf, { filename: "audio.wav", contentType: "audio/wav" });
    form.append("model", "whisper-1");
    form.append("response_format", "verbose_json");
    form.append("timestamp_granularities[]", "word");
    form.append("timestamp_granularities[]", "segment");

    const res = await fetch("https://api.openai.com/v1/audio/transcriptions", {
      method: "POST",
      headers: { Authorization: `Bearer ${process.env.OPENAI_API_KEY}`, ...form.getHeaders() },
      body: form,
    });

    const text = await res.text();
    if (!res.ok) throw new Error(text);

    return JSON.parse(text);
  }
);

/* =========================================================
   ğŸ“š 7) Storage: _subtitles.json â†’ Firestore(official_materials) è‡ªå‹•ç™»éŒ²
   ========================================================= */
exports.registerOfficialMaterialOnSubtitleCreated = onObjectFinalized(
  { region: "asia-northeast1" },
  async (event) => {
    const object = event.data;
    const filePath = object.name;
    if (!filePath) return;
    if (!isOfficialPath(filePath)) return;
    if (!isSubtitlesJson(filePath)) return;

    const bucket = storage.bucket(object.bucket);

    // å¯¾ã«ãªã‚‹éŸ³å£°ã‚’æ¢ã™ï¼ˆbase = ".../xxxx"ï¼‰
    const base = filePath.replace(/_subtitles\.json$/i, "");
    const candidates = [`${base}.mp3`, `${base}.wav`, `${base}.m4a`, `${base}.aac`, `${base}.ogg`];
    let audioPath = null;

    for (const c of candidates) {
      const [exists] = await bucket.file(c).exists();
      if (exists) {
        audioPath = c;
        break;
      }
    }
    if (!audioPath) {
      console.log("âš ï¸ audio not found for:", filePath);
      return;
    }

    // å­—å¹•æœ¬æ–‡
    const [buf] = await bucket.file(filePath).download();
    const subtitleJson = JSON.parse(buf.toString("utf-8"));
    const text = subtitleJson.text || "";
    const language = subtitleJson.language || "en";

    // âœ… Level/Lesson/Patternï¼ˆevaluationã¯Lessonç›´ä¸‹ã§ã‚‚pattern="evaluation"ã«ãªã‚‹ï¼‰
    const { level, lesson, pattern } = extractMetaFromOfficialPath(filePath);
    if (!level || !lesson || !pattern) {
      console.log("âš ï¸ meta missing:", filePath, { level, lesson, pattern });
      return;
    }

    // âœ… docIdã¯ â€œpatternå˜ä½â€ ã«çµ±ä¸€
    const patternDocId = toDocIdFromPath(`official/${level}/${lesson}/${pattern}`);

    // âœ… jaå­—å¹•ãŒæ—¢ã«ã‚ã‚‹ãªã‚‰ãƒ‘ã‚¹ã‚‚æŒãŸã›ã‚‹ï¼ˆãªãã¦ã‚‚nullã§OKï¼‰
    const jaSubtitlePath = toJaSubtitlesPath(filePath);
    let subtitleJaPath = null;
    if (jaSubtitlePath) {
      const [jaExists] = await bucket.file(jaSubtitlePath).exists();
      if (jaExists) subtitleJaPath = jaSubtitlePath;
    }

    const title =
      pattern === "evaluation"
        ? `${level}-${lesson}-evaluation`
        : `${level}-${lesson}-${pattern}`;

    await db.collection("official_materials").doc(patternDocId).set(
      {
        type: "Official",
        level,
        lesson,
        pattern,
        title,
        audioPath,
        subtitlePath: filePath,
        subtitleJaPath,
        text,
        language,
        updatedAt: admin.firestore.FieldValue.serverTimestamp(),
      },
      { merge: true }
    );

    console.log("âœ… registered official_materials:", patternDocId);
  }
);


/* =========================================================
   ğŸ”Š 8) Azure TTS (SSML) -> WAV buffer
   ========================================================= */
async function azureTtsToWavBuffer({ text, voiceName, rate }, { key, region }) {
  const ssml = `
<speak version="1.0" xml:lang="en-US">
  <voice xml:lang="en-US" name="${voiceName}">
    <prosody rate="${rate}">
      ${escapeXml(text)}
    </prosody>
  </voice>
</speak>`.trim();

  // token
  const tokenRes = await fetch(`https://${region}.api.cognitive.microsoft.com/sts/v1.0/issuetoken`, {
    method: "POST",
    headers: { "Ocp-Apim-Subscription-Key": key },
  });
  if (!tokenRes.ok) {
    const t = await tokenRes.text();
    throw new Error(`Azure token failed: ${tokenRes.status} ${t}`);
  }
  const token = await tokenRes.text();

  const ttsRes = await fetch(`https://${region}.tts.speech.microsoft.com/cognitiveservices/v1`, {
    method: "POST",
    headers: {
      Authorization: `Bearer ${token}`,
      "Content-Type": "application/ssml+xml",
      "X-Microsoft-OutputFormat": "riff-16khz-16bit-mono-pcm",
      "User-Agent": "shadow-speak-functions",
    },
    body: ssml,
  });

  if (!ttsRes.ok) {
    const t = await ttsRes.text();
    throw new Error(`Azure TTS failed: ${ttsRes.status} ${t}`);
  }

  const arrayBuf = await ttsRes.arrayBuffer();
  return Buffer.from(arrayBuf);
}

function escapeXml(s) {
  return (s || "")
    .replace(/&/g, "&amp;")
    .replace(/</g, "&lt;")
    .replace(/>/g, "&gt;")
    .replace(/"/g, "&quot;")
    .replace(/'/g, "&apos;");
}
/* =========================================================
   âœ… 9) Storage: official/*.txt â†’ WAV è‡ªå‹•ç”Ÿæˆï¼ˆLevel/Patternã§å£°&é€Ÿåº¦ï¼‰
   ========================================================= */
exports.generateMp3FromOfficialTxt = onObjectFinalized(
  {
    region: "asia-northeast1",
    timeoutSeconds: 540,
    memory: "1GiB",
    secrets: [SPEECH_KEY, SPEECH_REGION],
  },
  async (event) => {
    const object = event.data;
    const filePath = object.name;
    if (!filePath) return;

    // official ã® txt ã ã‘
    if (!isOfficialTxt(filePath)) return;

    // evaluation ã‚’ Lessonç›´ä¸‹ã«ç½®ãé‹ç”¨ã§ã‚‚æ‹¾ãˆã‚‹ã‚ˆã†ã«
    const { level, lesson, pattern } = extractMetaFromOfficialPath(filePath);
    if (!level || !lesson || !pattern) return;

    const bucket = storage.bucket(object.bucket);

    // å‡ºåŠ›å…ˆï¼ˆ.txt â†’ .wavï¼‰
    const outPath = toTtsAudioOutPathFromTxt(filePath);
    if (!outPath) return;

    // æ—¢ã«éŸ³å£°ãŒã‚ã‚‹ãªã‚‰ã‚¹ã‚­ãƒƒãƒ—ï¼ˆä½œã‚Šç›´ã—ãŸã„ãªã‚‰wavæ¶ˆã™ï¼‰
    const [exists] = await bucket.file(outPath).exists();
    if (exists) {
      console.log("â­ TTS audio exists. skip:", outPath);
      return;
    }

    // txt ã‚’èª­ã‚€
    const [buf] = await bucket.file(filePath).download();
    const text = buf.toString("utf-8").replace(/\s+/g, " ").trim();
    if (!text) {
      console.log("âš ï¸ empty txt:", filePath);
      return;
    }

    // è¨­å®šï¼ˆpatternâ†’voice, levelâ†’rateï¼‰
    const voiceName = pickVoiceName({ pattern });
    const rate = pickRate({ level });

    const key = process.env.SPEECH_KEY;
    const region = process.env.SPEECH_REGION;
    if (!key || !region) throw new Error("SPEECH_KEY / SPEECH_REGION missing");

    console.log("ğŸ™ TTS:", { filePath, outPath, level, lesson, pattern, voiceName, rate });

    const wavBuf = await azureTtsToWavBuffer({ text, voiceName, rate }, { key, region });

    await bucket.file(outPath).save(wavBuf, {
      contentType: "audio/wav",
      resumable: false,
      metadata: { cacheControl: "no-cache" },
    });

    console.log("âœ… TTS wav uploaded:", outPath);
  }
);


/* =========================================================
   âœ… 10) Dictationï¼ˆLesson/Pattern çµ±ä¸€1æœ¬ï¼‰
   - trigger: official/**/


const STOPWORDS = new Set([
  "the","a","an","and","or","but","so","to","of","in","on","at","for","from","with","as",
  "is","are","was","were","be","been","being","am",
  "i","you","he","she","it","we","they","me","him","her","them","my","your","his","their","our",
  "this","that","these","those",
  "not","no","yes","do","does","did","done",
  "have","has","had",
  "will","would","can","could","may","might","should","must"
]);

function normalizeWord(w) {
  return (w || "")
    .toString()
    .trim()
    .replace(/^[^\w']+|[^\w']+$/g, "")
    .toLowerCase();
}

function tokenize(text) {
  return (text || "")
    .replace(/\s+/g, " ")
    .trim()
    .split(/\s+/)
    .map(normalizeWord)
    .filter(Boolean);
}

function splitSentences(text) {
  const t = (text || "").replace(/\s+/g, " ").trim();
  if (!t) return [];
  return t.split(/(?<=[.!?])\s+/).map(s => s.trim()).filter(Boolean);
}

function uniqueWordsInText(text) {
  const seen = new Set();
  const out = [];
  for (const w of tokenize(text)) {
    if (seen.has(w)) continue;
    seen.add(w);
    out.push(w);
  }
  return out;
}

function pickAnswerWordsFromSnippet(snippet, n) {
  const candidates = uniqueWordsInText(snippet)
    .filter(w => w.length >= 4)
    .filter(w => !STOPWORDS.has(w))
    .filter(w => !/^\d+$/.test(w));
  return candidates.slice(0, n);
}

function replaceOnceWholeWord(text, word, replacement) {
  const escaped = word.replace(/[.*+?^${}()|[\]\\]/g, "\\$&");
  const re = new RegExp(`\\b${escaped}\\b`, "i");
  return text.replace(re, replacement);
}

function firstIndexOfWholeWord(text, word) {
  const escaped = word.replace(/[.*+?^${}()|[\]\\]/g, "\\$&");
  const re = new RegExp(`\\b${escaped}\\b`, "i");
  const m = re.exec(text);
  return m ? m.index : Number.POSITIVE_INFINITY;
}

// âœ… answersé †ï¼ç©ºæ‰€é † ã‚’ä¿è¨¼
function buildClozeFromSnippet(snippet, blankCount) {
  let out = (snippet || "").replace(/\s+/g, " ").trim();
  if (!out) return { sentence: "", answers: [] };

  // ã¾ãšå€™è£œèªã‚’ä½œã‚‹ï¼ˆãƒ¦ãƒ‹ãƒ¼ã‚¯èªï¼‰
  const pool = uniqueWordsInText(out)
    .filter(w => w.length >= 4)
    .filter(w => !STOPWORDS.has(w))
    .filter(w => !/^\d+$/.test(w));

  const picked = [];
  let working = out;

  // âœ… æ–‡ã®å·¦ã‹ã‚‰é †ã«ã€Œè¦‹ã¤ã‹ã£ãŸèªã€ã‚’æ¡ç”¨ã—ã¦ã„ã
  // ã“ã‚Œã§ answers ã®é †ç•ªï¼ç©ºæ‰€ã®é †ç•ª ãŒ100%ä¸€è‡´ã™ã‚‹
  while (picked.length < blankCount) {
    let best = null; // { w, idx }
    for (const w of pool) {
      if (picked.includes(w)) continue;
      const idx = firstIndexOfWholeWord(working, w);
      if (!Number.isFinite(idx)) continue;
      if (best == null || idx < best.idx) best = { w, idx };
    }
    if (!best) break;

    picked.push(best.w);
    working = replaceOnceWholeWord(working, best.w, "________");
  }

  const blanks = (working.match(/_{3,}/g) || []).length;
  const answers = picked.slice(0, blanks);

  return { sentence: working, answers };
}

function stableSortPassageMap(entries) {
  return entries.sort((a, b) => (a.passage || 999) - (b.passage || 999));
}

function jaccard(a, b) {
  const A = new Set(tokenize(a));
  const B = new Set(tokenize(b));
  if (A.size === 0 || B.size === 0) return 0;
  let inter = 0;
  for (const w of A) if (B.has(w)) inter++;
  const uni = A.size + B.size - inter;
  return uni ? inter / uni : 0;
}

function pickDistinctSnippets(snippets, count, { maxSim = 0.45 } = {}) {
  const picked = [];
  for (const s of snippets) {
    if (!s) continue;
    const ok = picked.every(p => jaccard(p, s) <= maxSim);
    if (ok) picked.push(s);
    if (picked.length >= count) break;
  }
  for (const s of snippets) {
    if (picked.length >= count) break;
    if (!picked.includes(s)) picked.push(s);
  }
  return picked.slice(0, count);
}

// âœ… â€œé•·ã‚â€ã‚’ç‹™ã£ã¦ 2æ–‡å–ã‚‹ï¼ˆCç”¨ï¼‰
function pickSnippetNSentences(mergedText, n) {
  const sents = splitSentences(mergedText);
  if (sents.length === 0) return "";
  if (n <= 1) return sents[0].trim();

  // ãªã‚‹ã¹ãè‡ªç„¶ãª2æ–‡ï¼ˆé•·ã™ããŸã‚‰1æ–‡ã«è½ã¨ã™ï¼‰
  const two = `${sents[0]} ${sents[1] || ""}`.trim();
  if (two.length <= 260 && (sents[1] || "").length > 0) return two;
  return sents[0].trim();
}

exports.generateDictationForLessonPattern = onObjectFinalized(
  { region: "asia-northeast1", timeoutSeconds: 540, memory: "1GiB" },
  async (event) => {
    const object = event.data;
    const filePath = object.name;
    if (!filePath) return;

    if (!isOfficialPath(filePath)) return;
    if (!isSubtitlesJson(filePath)) return;

    if (filePath.includes("/evaluation/")) return;
    if (filePath.includes("/dictation_audio/")) return;

    const { level, lesson, pattern } = extractMetaFromOfficialPath(filePath);
    if (!level || !lesson || !pattern) return;

    const bucket = storage.bucket(object.bucket);
    const dictPath = `official/${level}/${lesson}/${pattern}/dictation.json`;

    console.log("â™»ï¸ rebuild dictation.json:", dictPath);

    const prefix = `official/${level}/${lesson}/${pattern}/`;
    const [files] = await bucket.getFiles({ prefix });

    const subtitleFiles = files
      .map(f => f.name)
      .filter(p => isSubtitlesJson(p))
      .filter(p => !p.includes("/evaluation/"))
      .filter(p => !p.includes("/dictation_audio/"));

    if (subtitleFiles.length === 0) {
      console.log("âš ï¸ no subtitles found under:", prefix);
      return;
    }

    // passageã”ã¨ã«é›†ã‚ã‚‹
    const byPassage = new Map();
    for (const p of subtitleFiles) {
      const passage = extractPassageNumber(p) ?? 999;
      const [buf] = await bucket.file(p).download();
      const sub = JSON.parse(buf.toString("utf-8"));
      const t = (sub.text || "").replace(/\s+/g, " ").trim();
      if (!t) continue;

      if (!byPassage.has(passage)) byPassage.set(passage, { passage, texts: [] });
      byPassage.get(passage).texts.push(t);
    }

    const passages = stableSortPassageMap(Array.from(byPassage.values()));
    if (passages.length === 0) {
      console.log("âš ï¸ no valid passage text:", prefix);
      return;
    }

    // âœ… passageã”ã¨ã« merged ã‚’ä½œã‚Šã€ãã“ã‹ã‚‰ã€Œæ–‡ãƒªã‚¹ãƒˆã€ã‚’ä½œã‚‹
    const mergedList = passages
      .map(p => ({
        passage: p.passage,
        merged: p.texts.join(" ").replace(/\s+/g, " ").trim(),
      }))
      .filter(x => x.merged.length >= 20);

    if (mergedList.length === 0) {
      console.log("âš ï¸ no usable merged text:", prefix);
      return;
    }

    // âœ… å€™è£œã‚¹ãƒ‹ãƒšãƒƒãƒˆã‚’ä½œã‚‹
    // - passageãŒè¤‡æ•°ã‚ã‚‹ãªã‚‰åŸºæœ¬ã¯åˆ¥passageã‹ã‚‰å–ã‚Œã‚‹
    // - 1ã¤ã—ã‹ãªãã¦ã‚‚ã€æ–‡ã‚’ãƒãƒ©ã—ã¦è¤‡æ•°å€™è£œã‚’ä½œã‚‹
    let candidates = [];

    for (const m of mergedList) {
      const sents = splitSentences(m.merged);

      // 1æ–‡å€™è£œï¼ˆA/Bç”¨ï¼‰
      for (const s of sents) {
        const ss = s.trim();
        if (ss.length >= 20) candidates.push(ss);
      }

      // 2æ–‡å€™è£œï¼ˆCç”¨ã«é•·ã‚ï¼‰
      if (sents.length >= 2) {
        const two = `${sents[0]} ${sents[1]}`.trim();
        if (two.length >= 40) candidates.push(two);
      }
    }

    candidates = candidates
      .map(s => s.replace(/\s+/g, " ").trim())
      .filter(Boolean);

    // âœ… ä¼¼ã™ãå›é¿ã§ A/B/C ã‚’é¸ã¶ï¼ˆå€™è£œãŒå°‘ãªãã¦ã‚‚è£œå……ã•ã‚Œã‚‹ï¼‰
    const [sA, sB, sCraw] = pickDistinctSnippets(candidates, 3, { maxSim: 0.45 });

    // âœ… Cã¯ã€Œé•·ã‚å„ªå…ˆã€ã«å¯„ã›ã‚‹ï¼ˆ2æ–‡å€™è£œãŒã‚ã‚Œã°ãã£ã¡ã‚’ä½¿ã†ï¼‰
    // sCraw ãŒçŸ­ã‘ã‚Œã°ã€mergedå…ˆé ­2æ–‡ã‚’ä½¿ã†
    let sC = sCraw;
    if (!sC || sC.length < 80) {
      // ä¸€ç•ªé•·ããªã‚Šãã†ãª merged ã‹ã‚‰2æ–‡å–ã‚‹
      const longest = mergedList.slice().sort((a, b) => b.merged.length - a.merged.length)[0];
      sC = pickSnippetNSentences(longest.merged, 2);
    }

    const A1 = buildClozeFromSnippet(sA, 2);
    const B1 = buildClozeFromSnippet(sB, 3);

    // Cã¯é•·ã„ãªã‚‰4ã€çŸ­ã„ãªã‚‰3
    const wantC = (sC.length >= 120) ? 4 : 3;
    const C1 = buildClozeFromSnippet(sC, wantC);

    // text ã¯æ¡ç”¨ã—ãŸ3å•ã®å…ƒæ–‡ï¼ˆãƒ‡ãƒãƒƒã‚°ã«ã‚‚ä½¿ãˆã‚‹ï¼‰
    const textForDebug = [sA, sB, sC].filter(Boolean).join(" ").replace(/\s+/g, " ").trim();

    const out = {
      type: "dictation",
      lessonId: `${level}_${lesson}_${pattern}`,
      sourcePrefix: prefix,
      text: textForDebug,
      parts: {
        A: [{ id: "A1", sentence: A1.sentence, answers: A1.answers }],
        B: [{ id: "B1", sentence: B1.sentence, answers: B1.answers }],
        C: [{ id: "C1", sentence: C1.sentence, answers: C1.answers }],
      },
      createdAt: new Date().toISOString(),
    };

    await bucket.file(dictPath).save(JSON.stringify(out, null, 2), {
      contentType: "application/json",
      resumable: false,
      metadata: { cacheControl: "no-cache" },
    });

    console.log("âœ… dictation.json created:", dictPath);

    const patternDocId = toDocIdFromPath(`official/${level}/${lesson}/${pattern}`);
    await db.collection("official_materials").doc(patternDocId).set(
      {
        type: "Official",
        level,
        lesson,
        pattern,
        dictationPath: dictPath,
        updatedAt: admin.firestore.FieldValue.serverTimestamp(),
      },
      { merge: true }
    );
  }
);



/* =========================================================
   âœ… 11) DictationéŸ³å£° è‡ªå‹•ç”Ÿæˆï¼ˆdictation.json â†’ dictation_audio/**.wavï¼‰
   - trigger: official/**/

function fillBlanks(template, answers) {
  let idx = 0;
  return (template || "")
    .replace(/_{3,}/g, () => {
      const w = answers && idx < answers.length ? answers[idx] : "____";
      idx += 1;
      return w;
    })
    .replace(/\s+/g, " ")
    .trim();
}

function buildQuestionText(group, q) {
  const answers = q.answers || [];

  // A/C: sentence ã‚’åŸ‹ã‚æˆ»ã—ãŸå®Œå…¨æ–‡
  if (group === "A" || group === "B" || group === "C") {
    return fillBlanks(q.sentence || "", answers);
  }



  return "";
}

exports.generateDictationAudioFromDictationJson = onObjectFinalized(
  { region: "asia-northeast1", timeoutSeconds: 540, memory: "1GiB", secrets: [SPEECH_KEY, SPEECH_REGION] },
  async (event) => {
    const object = event.data;
    const filePath = object.name;
    if (!filePath) return;
    if (!isDictationJson(filePath)) return;

    const bucket = storage.bucket(object.bucket);

    const [buf] = await bucket.file(filePath).download();
    const dict = JSON.parse(buf.toString("utf-8"));

    const parts = dict.parts || {};
    const baseDir = filePath.replace(/\/dictation\.json$/i, ""); // official/Level5/Lesson3/D

    const key = process.env.SPEECH_KEY;
    const region = process.env.SPEECH_REGION;
    const voiceName = "en-US-JennyNeural";
    const rate = "0.85";

    const jobs = [];
    for (const group of ["A", "B", "C"]) {
      const qs = Array.isArray(parts[group]) ? parts[group] : [];
      for (const q of qs) {
        const id = q.id;
        if (!id) continue;
        const outPath = `${baseDir}/dictation_audio/${group}/${id}.wav`;
        jobs.push({ group, id, outPath, q });
      }
    }

    if (jobs.length === 0) {
      console.log("âš ï¸ no dictation questions:", filePath);
      return;
    }

    // æ—¢å­˜ãƒã‚§ãƒƒã‚¯ï¼ˆå…¨éƒ¨ã‚ã‚‹ãªã‚‰çµ‚äº†ï¼‰
    let allExist = true;
    for (const j of jobs) {
      const [ex] = await bucket.file(j.outPath).exists();
      if (!ex) { allExist = false; break; }
    }
    if (allExist) {
      console.log("â­ all dictation audio exists. skip.");
      return;
    }

    // ç”Ÿæˆ
    for (const j of jobs) {
      const [ex] = await bucket.file(j.outPath).exists();
      if (ex) continue;

      try {
        const text = buildQuestionText(j.group, j.q);
        if (!text) continue;

        const wavBuf = await azureTtsToWavBuffer(
          { text, voiceName, rate },
          { key, region }
        );

        await bucket.file(j.outPath).save(wavBuf, {
          contentType: "audio/wav",
          resumable: false,
          metadata: { cacheControl: "no-cache" },
        });

        console.log("âœ… dictation wav uploaded:", j.outPath);
      } catch (e) {
        console.error("âŒ dictation audio failed:", j.outPath, e);
      }
    }
  }
);
function toJaSubtitlesPath(p) {
  if (typeof p !== "string") return null;

  const lower = p.toLowerCase();

  // âœ… å¤‰ãªæ—§ãƒ«ãƒ¼ãƒ«ãŒæ¥ãŸã‚‰æ­£è¦åŒ–ã—ã¦è¿”ã™
  if (lower.endsWith("_subtitles_ja.json")) {
    return p.replace(/_subtitles_ja\.json$/i, "_ja.json");
  }

  // âœ… ã™ã§ã«æ­£ã—ã„ ja ãªã‚‰ä½•ã‚‚ã—ãªã„
  if (lower.endsWith("_ja.json")) return null;

  // âœ… è‹±èªå­—å¹•ï¼ˆWhisperç”Ÿæˆï¼‰: xxx_subtitles.json â†’ xxx_ja.json
  if (lower.endsWith("_subtitles.json")) {
    return p.replace(/_subtitles\.json$/i, "_ja.json");
  }

  // å¿µã®ãŸã‚
  if (lower.endsWith(".json")) {
    return p.replace(/\.json$/i, "_ja.json");
  }

  return null;
}


exports.generateJaSubtitleJson = onObjectFinalized(
  { region: "asia-northeast1", timeoutSeconds: 540, memory: "1GiB", secrets: [OPENAI_API_KEY] },
  async (event) => {
    const object = event.data;
    const filePath = object.name;
    if (!filePath) return;

    // âœ… å¯¾è±¡ã¯ã€ŒWhisperã§ä½œã£ãŸå­—å¹•JSONã€ã ã‘
    if (!isSubtitlesJson(filePath)) return;

    // âœ… evaluationã¯è¦ä»¶æ¬¡ç¬¬ï¼šä½œã‚ŠãŸã„ãªã‚‰å¤–ã•ãªã„ã€‚ä½œã‚ŠãŸããªã„ãªã‚‰ return;
    // if (filePath.includes("/evaluation/")) return;

    // âœ… ã™ã§ã«jaã¯ç„¡é™ãƒ«ãƒ¼ãƒ—é˜²æ­¢
    const jaPath = toJaSubtitlesPath(filePath);
    if (!jaPath) return;

    const bucket = storage.bucket(object.bucket);

    // æ—¢ã«å­˜åœ¨ã™ã‚‹ãªã‚‰ã‚¹ã‚­ãƒƒãƒ—
    const [exists] = await bucket.file(jaPath).exists();
    if (exists) {
      console.log("â­ ja subtitles exists. skip:", jaPath);
      return;
    }

    // å…ƒJSONã‚’èª­ã‚€
    const [buf] = await bucket.file(filePath).download();
    const src = JSON.parse(buf.toString("utf-8"));

    if (!Array.isArray(src.segments)) return;
    // languageãŒenã§ãªãã¦ã‚‚ç¿»è¨³ã—ãŸã„ãªã‚‰ã“ã®åˆ¤å®šã¯å¤–ã—ã¦OK
    // if (src.language && src.language !== "en") return;

    const jaJson = await translateSegmentsToJa(src, process.env.OPENAI_API_KEY);

    // ä¿å­˜ï¼ˆUTF-8ï¼‰
    await bucket.file(jaPath).save(JSON.stringify(jaJson, null, 2), {
      contentType: "application/json; charset=utf-8",
      resumable: false,
      metadata: { cacheControl: "no-cache" },
    });

    console.log("âœ… created ja subtitles:", jaPath);
  }
);

async function translateSegmentsToJa(src, apiKey) {
  if (!apiKey) throw new Error("OPENAI_API_KEY missing");

  // segmentsã ã‘é€ã‚‹ï¼ˆãƒˆãƒ¼ã‚¯ãƒ³ç¯€ç´„ï¼‰
  const input = {
    language: "ja",
    segments: src.segments.map((s) => ({
      id: s.id,
      start: s.start,
      end: s.end,
      text: s.text,
    })),
  };

  const payload = {
    model: "gpt-4.1-mini",
    temperature: 0.2,
    response_format: { type: "json_object" },
    messages: [
      { role: "system", content: "Translate English subtitle segments to natural Japanese. Keep id/start/end unchanged. Output JSON only." },
      { role: "user", content: JSON.stringify(input) },
    ],
  };

  const res = await fetch("https://api.openai.com/v1/chat/completions", {
    method: "POST",
    headers: { Authorization: `Bearer ${apiKey}`, "Content-Type": "application/json" },
    body: JSON.stringify(payload),
  });

  const text = await res.text();
  if (!res.ok) throw new Error(text);

  const data = JSON.parse(text);
  const content = data.choices?.[0]?.message?.content;
  const out = JSON.parse(content);

  // å¿µã®ãŸã‚ timing ã¯å…ƒã‚’å¼·åˆ¶æ¡ç”¨ï¼ˆã‚ºãƒ¬é˜²æ­¢ï¼‰
  return {
    language: "ja",
    text: "", // å¿…è¦ãªã‚‰å¾Œã§ segments é€£çµã§ä½œã£ã¦ã‚‚OK
    segments: src.segments.map((s, i) => ({
      id: s.id,
      start: s.start,
      end: s.end,
      text: out.segments?.[i]?.text ?? "",
    })),
  };
}
